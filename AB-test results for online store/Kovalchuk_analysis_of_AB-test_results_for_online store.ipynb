{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ результатов А/В-теста для интернет-магазина <a name=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследование проведено для отдела маркетинга интернет-магазина с целью приоритезировать список гипотез о способах увеличения выручки компании, а также проанализировать результаты А/В-теста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Оглавление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Часть 1. Изучение и приоритезация рабочих гипотез](#1)\n",
    "\n",
    "   [1.1 Загрузка необходимых для анализа библиотек](#1.1)  \n",
    "   [1.2 Изучение файла с гипотезами](#1.2)  \n",
    "   [1.3 Приоритезация гипотез](#1.3)  \n",
    "   [1.4 Выводы](#1.4)\n",
    "\n",
    "#### [Часть 2. Первичное изучение полученных в ходе A/B-теста данных](#2)\n",
    "\n",
    "   [2.1 Загрузка файлов с данными](#2.1)  \n",
    "   [2.2 Выводы: описание полученных данных](#2.2)  \n",
    "   [2.3 Изменение типов данных](#2.3)  \n",
    "\n",
    "#### [Часть 3. Анализ A/B-теста](#3)\n",
    "\n",
    "   [3.1 Оценка кумулятивных показателей выручки, среднего чека и конверсий](#3.1)  \n",
    "   [3.2 Поиск и устранение аномалий в результатах теста](#3.2)  \n",
    "   [3.3 Статистическое исследование результатов](#3.3)  \n",
    "   [3.4 Итоги анализа результатов А/В-теста](#3.4)    \n",
    "\n",
    "#### [Часть 4. Итоговые выводы исследования](#4)\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Часть 1. Изучение и приоритезация рабочих гипотез <a name='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Загрузка необходимых для анализа библиотек <a name='1.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from scipy import stats as st\n",
    "import math as mth\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Изучение файла с гипотезами <a name='1.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_data_file = \"datasets/AB-test_for_online_store.csv\"\n",
    "ab_test_data_orders = \"/Users/ivan/git_ucylama/learning_project/da_yandex/datasets/AB-test_for_online_store_orders.csv\"\n",
    "ab_test_data_visitors = \"/Users/ivan/git_ucylama/learning_project/da_yandex/datasets/AB-test_for_online_store_visitors.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File datasets/AB-test_for_online_store.csv does not exist: 'datasets/AB-test_for_online_store.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-09fad3c9f326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# загрузим файл с гипотезами\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis_data_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# выведем общую информацию о датафрейме\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File datasets/AB-test_for_online_store.csv does not exist: 'datasets/AB-test_for_online_store.csv'"
     ]
    }
   ],
   "source": [
    "# загрузим файл с гипотезами\n",
    "hypothesis = pd.read_csv(hypothesis_data_file)\n",
    "\n",
    "# выведем общую информацию о датафрейме\n",
    "hypothesis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скорректируем названия столбцов\n",
    "hypothesis = hypothesis.rename(columns={'Hypothesis':'hypothesis',\n",
    "                           'Reach':'reach',\n",
    "                           'Impact':'impact',\n",
    "                           'Confidence':'confidence',\n",
    "                           'Efforts':'efforts'})\n",
    "\n",
    "# увеличим ширину колонок\n",
    "pd.set_option('max_colwidth', 120)\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "# изучим первые строки таблицы и проверим результат\n",
    "display(hypothesis.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Данные в таблице отображаются корректно**, нет пропусков и необходимости работать с типами данных. В таблице содержится информация об оценках гипотез по ряду критериев, необходимых для их приоритезации. В датафрейме описаны следующие колонки (для удобства и аккуратности кода наименования колонок были переведены в единый нижний регистр):  \n",
    "* `hypothesis` — краткое описание гипотезы;  \n",
    "* `reach` — охват пользователей;  \n",
    "* `impact` — влияние на пользователей;  \n",
    "* `confidence` — уверенность в гипотезе;  \n",
    "* `efforts` — затраты ресурсов на проверку гипотезы (чем выше оценка, тем дороже реализация).  \n",
    "\n",
    "Все параметры оценок считаются по 10-бальной шкале.\n",
    "  \n",
    "**На данный момент у нас 9 рабочих гипотез, которые необходимо приоритезировать.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Приоритезация гипотез <a name='1.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для приоритезации гипотез используем фреймворки RICE и ICE, которые рассчитываются по формулам:  \n",
    "  \n",
    "$$ICE = \\frac{Impact * Confidence}{Efforts}$$\n",
    "  \n",
    "$$RICE = \\frac{Rearch * Impact * Confidence}{Efforts}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитаем показатель ICE и округлим до 1 занка после запятой\n",
    "hypothesis['ice_score'] = round(hypothesis['impact'] * hypothesis['confidence'] / hypothesis['efforts'], 1)\n",
    "\n",
    "# отсортируем по убыванию приоритета и выведем топ-3\n",
    "hypothesis[['hypothesis', 'ice_score']].sort_values(by='ice_score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитаем показатель RICE\n",
    "hypothesis['rice_score'] = (hypothesis['reach'] \n",
    "                            * hypothesis['impact'] \n",
    "                            * hypothesis['confidence'] \n",
    "                            / hypothesis['efforts']\n",
    "                           )\n",
    "\n",
    "# отсортируем по убыванию приоритета и выведем топ-3\n",
    "hypothesis[['hypothesis', 'rice_score']].sort_values(by='rice_score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Выводы <a name='1.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки приоритета гипотез применили метод ICE и его модификацию — RICE. Расчитать первый показатель можно по формуле `ICE = (Impact x Confidence) / Efforts`, а второй — `RICE score = (Reach x Impact x Confidence) / Efforts`. В топ-5 в обоих случаях вошли гипотезы 0, 2, 6, 7 и 8, но их порядок по убыванию приоритета различается. Это связано с тем, что метод RICE учитывает дополнительный параметр `reach` — охват пользователей, которых затронет изменение. Наилучший пример силы влияния одного этого параметра можно проследить на гипотезе 7, для которой ICE=16.2, а RICE=112, так как параметр охвата оценен в 10 (затронет всех пользователей).  \n",
    "  \n",
    "Так как метод RICE учитывает больше параметров при оценке приоритета гипотез, рекомендуем ориентироваться на него (метод ICE подтверждает, что оценки выставлены корректно и топ-5 гипотез совпадает по составу). \n",
    "  \n",
    "**Выделим топ-3 по показателю RICE:**  \n",
    "1. Добавить форму подписки на все основные страницы, чтобы собрать базу клиентов для email-рассылок  \n",
    "2. Добавить блоки рекомендаций товаров на сайт интернет магазина, чтобы повысить конверсию и средний чек заказа  \n",
    "3. Добавить два новых канала привлечения трафика, что позволит привлекать на 30% больше пользователей  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Первичное изучение полученных в ходе A/B-теста данных <a name='2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Загрузка файлов с данными <a name='2.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим данные А/В-теста о сделанных заказах\n",
    "orders_data = pd.read_csv(ab_test_data_orders)\n",
    "orders_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переименуем названия колонок для удобства и приведем их в единый формат\n",
    "orders_data = orders_data.rename(columns={'transactionId':'transaction_id',\n",
    "                                          'visitorId':'visitor_id'})\n",
    "\n",
    "# общая информация о данных в датафрейме orders_data\n",
    "orders_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# загрузим данные А/В-теста о посещениях сайта\n",
    "visitors_data = pd.read_csv(ab_test_data_visitors)\n",
    "visitors_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# общая информация о данных в датафрейме visitors_data\n",
    "visitors_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Выводы: описание полученных данных <a name='2.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты проведенного А/В-теста хранятся в двух датафреймах.  \n",
    "  \n",
    "В таблице `orders_data` хранятся данные о сделанных заказах, 5 колонок:  \n",
    "* `transaction_id` — уникальный ID заказа (тип данных `int64`)  \n",
    "* `visitor_id` — уникальный ID клиента, сделавшего заказ (тип данных `int64`)  \n",
    "* `date` — дата, когда сделан заказ (тип данных `object`)  \n",
    "* `revenue` — выручка с заказа (тип данных `int64`)  \n",
    "* `group` — идентификатор группы \"А\" или \"В\" (тип данных `object`)  \n",
    "\n",
    "В таблице `orders_data` дубликатов не обнаружено, нет пропусков в данных, но необходимо скорректировать тип данных колонки `date` и перевести в формат `datetime`.  \n",
    "  \n",
    "В таблице `visitors_data` хранятся данные о посещениях сайта по дням, 3 колонки:  \n",
    "* `date` — дата посещения (тип данных `object`)  \n",
    "* `group` — идентификатор тестовой группы (тип данных `object`)  \n",
    "* `visitors` — количество визитов в день для группы (тип данных `int64`)  \n",
    "\n",
    "В таблице `visitors_data` дубликатов не обнаружено, нет пропусков в данных, но необходимо скорректировать тип данных колонки `date` и перевести в формат `datetime`.  \n",
    "  \n",
    "Перед началом анализа результатов теста, приведем данные к нужному виду в следующем пункте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Изменение типов данных <a name='2.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменим тип данных в колонках date на корректний\n",
    "for data in (orders_data, visitors_data):\n",
    "    data['date'] = data['date'].map(lambda x: dt.datetime.strptime(x, '%Y-%m-%d'))\n",
    "    # проверка\n",
    "    display(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Анализ A/B-теста <a name='3'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Оценка кумулятивных показателей выручки, среднего чека и конверсий <a name='3.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим датафрейм с комулятивными данными результатов А/В-теста\n",
    "\n",
    "# шаг 1: создаем массив уникальных пар значений дат и групп теста\n",
    "dates_groups = orders_data[['date', 'group']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# шаг 2: соберем агрегированные кумулятивные по дням данные о заказах\n",
    "orders_aggregated = (dates_groups\n",
    "                     .apply(lambda x: \n",
    "                            # условия формирования среза данных\n",
    "                            orders_data[np.logical_and(orders_data['date'] <= x['date'], \n",
    "                                                       orders_data['group'] == x['group'])]\n",
    "                            # агрегирующая функция для среза\n",
    "                            .agg({'date':'max', \n",
    "                                  'group':'max', \n",
    "                                  'transaction_id':pd.Series.nunique, \n",
    "                                  'visitor_id':pd.Series.nunique, \n",
    "                                  'revenue':'sum'}),\n",
    "                            # применяем метод apply к каждой строке\n",
    "                            axis=1)\n",
    "                     .sort_values(by=['date', 'group'])\n",
    ")\n",
    "\n",
    "# проверим результат выполнения шага 2\n",
    "orders_aggregated.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# шаг 3: соберем агрегированные кумулятивные данные по дням о посещениях сайта\n",
    "visitors_aggregated = (dates_groups\n",
    "                       .apply(lambda x: \n",
    "                              # условия формирования среза данных\n",
    "                              visitors_data[np.logical_and(visitors_data['date'] <= x['date'],\n",
    "                                                           visitors_data['group'] == x['group'])]\n",
    "                              # агрегирующая функция для среза\n",
    "                              .agg({'date':'max', \n",
    "                                    'group':'max', \n",
    "                                    'visitors':'sum'}),\n",
    "                              # применяем метод apply к каждой строке\n",
    "                              axis=1)\n",
    "                       .sort_values(by=['date', 'group'])\n",
    ")\n",
    "\n",
    "# проверим результат выполнения шага 3\n",
    "visitors_aggregated.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# шаг 4: # объединим кумулятивные данные в одной таблице\n",
    "cumulative_data = orders_aggregated.merge(visitors_aggregated, left_on=['date', 'group'], right_on=['date', 'group'])\n",
    "# переименуем название столбцов\n",
    "cumulative_data.columns = ['date', 'group', 'orders', 'buyers', 'revenue', 'visitors']\n",
    "# проверим результат\n",
    "cumulative_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# датафрейм с кумулятивным кол-ом заказов и кмулятивной выручкой для группы А\n",
    "cumulative_revenue_a = cumulative_data[cumulative_data['group'] == 'A'][['date', 'revenue', 'orders']]\n",
    "# датафрейм с кумулятивным кол-ом заказов и кмулятивной выручкой для группы B\n",
    "cumulative_revenue_b = cumulative_data[cumulative_data['group'] == 'B'][['date', 'revenue', 'orders']]\n",
    "\n",
    "# построим график кумулятивной выручки по группам\n",
    "sns.set(rc={'figure.figsize':(19, 7)}, style='darkgrid', palette='rainbow')\n",
    "\n",
    "plt.plot(cumulative_revenue_a['date'], cumulative_revenue_a['revenue'], label='A')\n",
    "plt.plot(cumulative_revenue_b['date'], cumulative_revenue_b['revenue'], label='B')\n",
    "\n",
    "plt.title('Динамика кумулятивной выручки по группам')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Сумма выручки')\n",
    "plt.legend(title='Группы теста')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике видно, что выручка почти равномерно увеличивается в течение теста. В группе А рост происходит плавно и равномерно, а в группе В наблюдаем резкий скачок во второй половине августа. Это может говорить о наличии аномалий в количестве заказов или появлении нетипично дорогих заказов в выборке. На это необходимо обратить внимание при оценке результатов теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим график кумулятивного среднего чека по группам\n",
    "plt.plot(cumulative_revenue_a['date'], cumulative_revenue_a['revenue']/cumulative_revenue_a['orders'], label='A')\n",
    "plt.plot(cumulative_revenue_b['date'], cumulative_revenue_b['revenue']/cumulative_revenue_b['orders'], label='B')\n",
    "\n",
    "plt.title('Динамика кумулятивного среднего чека по группам')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Средний чек')\n",
    "plt.legend(title='Группы теста')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале средний сильно колебался для обоих групп, далее наблюдается рост в группе А и постепенный переход к равномерным колебаниям. Картину в группе В мешает оценить резкий всплеск 18-19 августа, после которого показатель начинает постепенно снижаться. Есть вероятность, что в обеих группах выбросы в виде аномально дорогих заказов влияют на результаты теста (для группы А такие заказы могли возникнуть с 11 по 13 августа). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим график относительного изменения кумулятивного среднего чека группы B к группе A\n",
    "\n",
    "# подготовим данные к анализу\n",
    "merged_cumulative_revenue = cumulative_revenue_a.merge(cumulative_revenue_b, \n",
    "                                                       left_on='date', \n",
    "                                                       right_on='date', \n",
    "                                                       how='left', \n",
    "                                                       suffixes=['_a', '_b'])\n",
    "\n",
    "# построим график отношения средних чеков\n",
    "plt.plot(merged_cumulative_revenue['date'], \n",
    "         (merged_cumulative_revenue['revenue_b']/merged_cumulative_revenue['orders_b'])\n",
    "         /(merged_cumulative_revenue['revenue_a']/merged_cumulative_revenue['orders_a'])-1,\n",
    ")\n",
    "\n",
    "plt.title('Относительное изменение кумулятивного среднего чека группы В к группе А')\n",
    "plt.xlabel('Дата')\n",
    "plt.axhline(y=0, color='grey', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резкие перепады значений в графике различия между сегментами подтверждают наличие дорогих заказов, которые влияют на результат теста и могут считаться выбросами. Эти заказы необходимо найти, изучить и, если это будет возможно, исключить из данных для проведения статистических тестов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# подсчитаем кумулятивную конверсию\n",
    "cumulative_data['conversion'] = cumulative_data['orders'] / cumulative_data['visitors']\n",
    "# выделим группу А\n",
    "cumulative_conversion_a = cumulative_data[cumulative_data['group'] == 'A']\n",
    "# выделим группу B\n",
    "cumulative_conversion_b = cumulative_data[cumulative_data['group'] == 'B']\n",
    "\n",
    "# построим график кумулятивной конверсии по группам\n",
    "plt.plot(cumulative_conversion_a['date'], cumulative_conversion_a['conversion'], label='A')\n",
    "plt.plot(cumulative_conversion_b['date'], cumulative_conversion_b['conversion'], label='B')\n",
    "\n",
    "plt.title('Кумулятивная конверсия по группам')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Конверсия')\n",
    "plt.legend(title='Группы теста')\n",
    "plt.ylim(0, 0.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале теста конверсия группы В вырвалась вперед, а конверсия группы А, лидирующей первые дни теста, постепенно снижалась. Через 10-13 дней конверсии в обеих группах начали равномерно колебаться вокруг усредненного значения, при этом группа В сохранила прочное лидерство и на первый взгляд может показаться эффективнее — об этом судить пока рано. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим график относительного изменения кумулятивной конверсии группы B к группе A\n",
    "merged_cumulative_conversion = (cumulative_conversion_a\n",
    "                                .merge(cumulative_conversion_b, \n",
    "                                       left_on='date', right_on='date',\n",
    "                                       how='left',\n",
    "                                       suffixes=['_a', '_b']))\n",
    "\n",
    "plt.plot(merged_cumulative_conversion['date'],\n",
    "         (merged_cumulative_conversion['conversion_b']/merged_cumulative_conversion['conversion_a']-1))\n",
    "\n",
    "plt.title('Относительное изменение кумулятивной конверсии группы В к группе А')\n",
    "plt.xlabel('Дата')\n",
    "plt.axhline(y=0, color='silver', linestyle='--')\n",
    "plt.axhline(y=0.14, color='grey', linestyle='--')\n",
    "plt.ylim(-0.3, 0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале теста группа В то выигрывала, то проигрывала группе А. Через 5 дней теста конверсия группы В относительно группы А начала расти и быстро опередила группу А, больше не снижалась, продолжая колебаться. После 17 дней теста конверсии группы В начали снижаться и только в конце месяца стал вновь наблюдаться рост.  \n",
    "  \n",
    "На данном этапе видим, что колебания конверсии еще не установились и делать выводы по тесту пока нельзя, сначала необходимо проанализировать аномалии и изучить поведение сегментов без них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Поиск и устранение аномалий в результатах теста <a name='3.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовим данные\n",
    "orders_by_users = (orders_data\n",
    "                   .drop(['group', 'revenue', 'date'], axis=1)\n",
    "                   .groupby('visitor_id', as_index=False)\n",
    "                   .agg({'transaction_id':pd.Series.nunique})\n",
    ")\n",
    "\n",
    "orders_by_users.columns = ['visitor_id', 'orders']\n",
    "\n",
    "# изучим первые строки датафрейма\n",
    "orders_by_users.sort_values(by='orders', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим точечный график количества заказов по пользователям\n",
    "x_values_new = pd.Series(range(0, len(orders_by_users['visitor_id'])))\n",
    "plt.scatter(x_values_new, orders_by_users['orders'])\n",
    "\n",
    "plt.title('Суммарное количество заказов по пользователям')\n",
    "plt.xlabel('Клиенты')\n",
    "plt.ylabel('Заказы (шт)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обозначим границу для определения аномальных пользователей\n",
    "np.percentile(orders_by_users['orders'], [95, 97, 99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике видно, что большая часть заказов не превышает значения 2, однако, есть достаточное количество пользователей, которые делали от 2 до 4 заказов, чтобы определить границу аномалии, мы подсчитали персентили: не более 3% пользователей делают более 2 заказов и только 1% пользователей делает более 4 заказов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим точечный график стоимостей заказов\n",
    "x_values = pd.Series(range(0, len(orders_data['revenue'])))\n",
    "plt.scatter(x_values, orders_data['revenue'])\n",
    "\n",
    "plt.title('Стоимость заказов')\n",
    "plt.xlabel('Заказы клиентов')\n",
    "plt.ylabel('Стоимость')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обозначим границу для определения аномальных заказов\n",
    "np.percentile(orders_data['revenue'], [95, 97, 99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике видно, что аномально дорогих заказов не так много, но один из них сделан на сумму более 1,2 млн — это однозначно влияет на результаты теста. Далее мы выявили, что только 5% заказов дороже 28000 и только 1% превышает сумму 58233.  \n",
    "  \n",
    "**За аномальные значения возьмем заказы на сумму более 35000 (~3%) и пользователей, сделавших 5 и более заказов (1%)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Статистическое исследование результатов <a name='3.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Анализ результатов А/В-теста по \"сырым\" данным**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расчитаем статистическую значимость различий в конверсии между группами по «сырым» данным\n",
    "\n",
    "# вычислим кол-во визитов в день по группам\n",
    "visitors_per_day_a = visitors_data[visitors_data['group'] == 'A'][['date', 'visitors']]\n",
    "visitors_per_day_a.columns = ['date', 'visitors_a']\n",
    "\n",
    "visitors_per_day_b = visitors_data[visitors_data['group'] == 'B'][['date', 'visitors']]\n",
    "visitors_per_day_b.columns = ['date', 'visitors_b']\n",
    "\n",
    "# переменные с данными о пользователях, сделавших хотя бы 1 заказ\n",
    "users_orders_a = (orders_data[orders_data['group'] == 'A']\n",
    "                  .groupby('visitor_id', as_index=False)\n",
    "                  .agg({'transaction_id':'nunique'})\n",
    ")\n",
    "users_orders_a.columns = ['user_id', 'orders_cnt']\n",
    "\n",
    "users_orders_b = (orders_data[orders_data['group'] == 'B']\n",
    "                  .groupby('visitor_id', as_index=False)\n",
    "                  .agg({'transaction_id':'nunique'})\n",
    ")\n",
    "users_orders_b.columns = ['user_id', 'orders_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим переменные для проверки выборок критерием Манна_Уитни\n",
    "sample_a_raw = pd.concat([users_orders_a['orders_cnt'], \n",
    "                      pd.Series(0, index=np.arange(visitors_per_day_a['visitors_a'].sum() \n",
    "                                                   - len(users_orders_a['orders_cnt'])), name='orders')], \n",
    "                     axis=0)\n",
    "\n",
    "sample_b_raw = pd.concat([users_orders_b['orders_cnt'], \n",
    "                      pd.Series(0, index=np.arange(visitors_per_day_b['visitors_b'].sum() \n",
    "                                                   - len(users_orders_b['orders_cnt'])), name='orders')],\n",
    "                      axis=0)\n",
    "\n",
    "alpha = .05 # критический уровень статистической значимости\n",
    "\n",
    "# применим критерий Манна_Уитни и рассчитаем относительную конверсию\n",
    "results_convertion_raw = st.mannwhitneyu(sample_a_raw, sample_b_raw)\n",
    "\n",
    "print('Значение p-value по критерию Манна-Уитни: {0:.3f}'.format(results_convertion_raw.pvalue))\n",
    "if (results_convertion_raw.pvalue < alpha):\n",
    "    print('Отвергаем нулевую гипотезу: разница статистически значима')\n",
    "else:\n",
    "    print(\"Не получилось отвергнуть нулевую гипотезу, вывод о различии сделать нельзя\")\n",
    "\n",
    "print()\n",
    "\n",
    "print('Относительный прирост конверсии группы B: {0:.3f}'.format(sample_b_raw.mean()/sample_a_raw.mean()-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в данных наблюдаются выбросы, применили u-критерий Манна-Уитни для проверки статистической значимости различий в конверсии групп А и В. По \"сырым\" данным получили значение p-value меньше 0.05, что означает, что **отвергаем нулевую гипотезу о том, что статистически значимых различий в конверсии между группами А и В нет**. Относительный прирост конверсии группы В составил 13.8%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расчитаем статистическую значимость различий в среднем чеке заказа между группами по «сырым» данным\n",
    "results_avg_check_raw = st.mannwhitneyu(orders_data[orders_data['group'] == 'A']['revenue'], \n",
    "                                        orders_data[orders_data['group'] == 'B']['revenue'])\n",
    "\n",
    "print('Значение p-value по критерию Манна-Уитни: {0:.3f}'.format(results_avg_check_raw.pvalue))\n",
    "if (results_avg_check_raw.pvalue < alpha):\n",
    "    print('Отвергаем нулевую гипотезу: разница статистически значима')\n",
    "else:\n",
    "    print(\"Не получилось отвергнуть нулевую гипотезу, вывод о различии сделать нельзя\")\n",
    "\n",
    "print()\n",
    " \n",
    "print('Относительный прирост среднего чека группы B: {0:.3f}'\n",
    "      .format(orders_data[orders_data['group'] == 'B']['revenue'].mean()\n",
    "              /orders_data[orders_data['group'] == 'A']['revenue'].mean()\n",
    "              -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение p-value значительно превышает критический уровень статистической значимости 0.05, что означает — **отвергнуть нулевую гипотезу не можем: причин считать, что в среднем чеке есть различия — нет.** При этом относительный прирост среднего чека группы В составил 25.9% — значительная разница, которая может быть вызвана выбросами в виде очень дорогих заказов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим аномальные значения:\n",
    "# заказы на сумму более 35000 (~3%) и пользователей, сделавших 5 и более заказов (1%)\n",
    "abnormal_orders = pd.concat([users_orders_a[users_orders_a['orders_cnt'] > 4]['user_id'],\n",
    "                             users_orders_b[users_orders_b['orders_cnt'] > 4]['user_id']], axis=0)\n",
    "abnormal_revenue = orders_data[orders_data['revenue'] > 35000]['visitor_id']\n",
    "abnormal_revenue.name = 'user_id'\n",
    "\n",
    "# список id \"аномальных\" пользователей \n",
    "abnormal_users = pd.concat([abnormal_orders, abnormal_revenue], axis=0).drop_duplicates().sort_values()\n",
    "# узнаем кол-во таких пользователей\n",
    "abnormal_users.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Анализ результатов А/В-теста по \"очищенным\" данным**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расчитаем статистическую значимость различий в конверсии между группами по «очищенным» данным\n",
    "sample_a_filtered = pd.concat([users_orders_a[np.logical_not(users_orders_a['user_id']\n",
    "                                                             .isin(abnormal_users))]['orders_cnt'], \n",
    "                               pd.Series(0, index=np.arange(visitors_per_day_a['visitors_a'].sum() \n",
    "                                                            - len(users_orders_a['orders_cnt'])), name='orders')], \n",
    "                               axis=0)\n",
    "\n",
    "sample_b_filtered = pd.concat([users_orders_b[np.logical_not(users_orders_b['user_id']\n",
    "                                                             .isin(abnormal_users))]['orders_cnt'], \n",
    "                               pd.Series(0, index=np.arange(visitors_per_day_b['visitors_b'].sum() \n",
    "                                                            - len(users_orders_b['orders_cnt'])), name='orders')], \n",
    "                               axis=0)\n",
    "\n",
    "result_convertion_filtered = st.mannwhitneyu(sample_a_filtered, sample_b_filtered)\n",
    "print('Значение p-value по критерию Манна-Уитни: {0:.3f}'.format(result_convertion_filtered.pvalue))\n",
    "\n",
    "if (result_convertion_filtered.pvalue < alpha):\n",
    "    print('Отвергаем нулевую гипотезу: разница статистически значима')\n",
    "else:\n",
    "    print(\"Не получилось отвергнуть нулевую гипотезу, вывод о различии сделать нельзя\")\n",
    "\n",
    "print()\n",
    "print('Относительный прирост конверсии группы B: {0:.3f}'\n",
    "      .format(sample_b_filtered.mean()/sample_a_filtered.mean()-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам теста, проведенного по очищенным данным, по-прежнему отвергаем нулевую гипотезу и можем считать, что разница между конверсиями групп А и В статистически значима. Однако теперь группа В лидирует относительно группы А на 15.7% — это говорит о том, что выбросы значительно влияли на относительные показатели конверсии и считать группу А более успешной по показателям конверсии было бы ошибочно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расчитаем статистическую значимость различий в среднем чеке заказа между группами по «очищенным» данным\n",
    "results_avg_check_filtered = st.mannwhitneyu(\n",
    "    orders_data[np.logical_and(orders_data['group'] == 'A', \n",
    "                               np.logical_not(orders_data['visitor_id'].isin(abnormal_users)))]['revenue'], \n",
    "    orders_data[np.logical_and(orders_data['group'] == 'B', \n",
    "                               np.logical_not(orders_data['visitor_id'].isin(abnormal_users)))]['revenue'])\n",
    "\n",
    "print('Значение p-value по критерию Манна-Уитни: {0:.3f}'.format(results_avg_check_filtered.pvalue))\n",
    "if (results_avg_check_filtered.pvalue < alpha):\n",
    "    print('Отвергаем нулевую гипотезу: разница статистически значима')\n",
    "else:\n",
    "    print(\"Не получилось отвергнуть нулевую гипотезу, вывод о различии сделать нельзя\")\n",
    "\n",
    "print()\n",
    "\n",
    "print('Относительный прирост среднего чека группы B: {0:.3f}'.format(\n",
    "    orders_data[np.logical_and(orders_data['group'] == 'B', \n",
    "                               np.logical_not(orders_data['visitor_id'].isin(abnormal_users)))]['revenue'].mean()\n",
    "    /orders_data[np.logical_and(orders_data['group'] == 'A', \n",
    "                                np.logical_not(orders_data['visitor_id'].isin(abnormal_users)))]['revenue'].mean()\n",
    "    -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменений в проверке статистической значимости различия средних чеков по группам после очистки данных от выбросов нет, показатель относительного прироста отражает отсутствие различий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Итоги анализа результатов А/В-теста <a name='3.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе исследования обнаружили:  \n",
    "* есть статистически значимое различие по конверсии между группами А и В как по \"сырым\", так и по очищенным от выбросов данным,  \n",
    "* по относительной конверсии группа В лидирует на 13.% по \"сырым\" данным и на 15.7% по очищенным,    \n",
    "* по графику относительного изменения кумулятивной конверсии (группы В к группе А) лидирует группа В,  \n",
    "* график относительного различия кумулятивного среднего чека показывает, что после нескольких резких колебаний группа В вышла вперед, однако, после постепенно значение начало снижаться и так и не вышло на плато, относительный прирост среднего чека группы В по очищенным данным составил -3.3%,  \n",
    "* статистически значимого различия по среднему чеку между группами А и В как по \"сырым\" данным, так и после удаления аномалий нет.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 4. Итоговые выводы исследования <a name='4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ результатов А/В-теста показал наличие статистического различия по конверсии между группами, при этом относительный прирост конверсии группы В составил 15.7%. Статистической значимости различий между группами по среднему чеку нет.  \n",
    "  \n",
    "**Продолжать А/В-тест далее нецелесообразно**, так как кумулятивные показатели для групп А и В выровнялись и зафиксировались (график \"Кумулятивная конверсия по группам\") и маловероятно, что группа А покажет рост конверсии в дальнейшем. Группу В можно считать эффективнее группы А по показателю конверсии.  \n",
    "  \n",
    "При запуске новых тестов, рекомендуем обратить внимание на приоритеты гипотез, которые мы выявили с помощью фреймворков RICE и ICE. Гипотезы, которые вошли в топ-3 по приоритетности:  \n",
    "* добавить форму подписки на все основные страницы, чтобы собрать базу клиентов для email-рассылок,  \n",
    "* добавить блоки рекомендаций товаров на сайт интернет-магазина, чтобы повысить конверсию и средний чек заказа,  \n",
    "* добавить два новых канала привлечения трафика, что позволит привлекать на 30% больше пользователей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "**<center>[Перейти в начало исследования](#0)</center>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
